commit b5a5268dabb2a4dea1c3c543a1ddff501b87a447
Author: jbrockmendel <jbrockmendel@gmail.com>
Date:   Tue Sep 8 18:33:41 2020 -0700

    STY: De-privatize imported names (#36235)

diff --git a/pandas/_libs/interval.pyx b/pandas/_libs/interval.pyx
index 931ad8326..f8bcbcfb1 100644
--- a/pandas/_libs/interval.pyx
+++ b/pandas/_libs/interval.pyx
@@ -46,7 +46,7 @@ from pandas._libs.tslibs.util cimport (
     is_timedelta64_object,
 )

-_VALID_CLOSED = frozenset(['left', 'right', 'both', 'neither'])
+VALID_CLOSED = frozenset(['left', 'right', 'both', 'neither'])


 cdef class IntervalMixin:
@@ -318,7 +318,7 @@ cdef class Interval(IntervalMixin):
         self._validate_endpoint(left)
         self._validate_endpoint(right)

-        if closed not in _VALID_CLOSED:
+        if closed not in VALID_CLOSED:
             raise ValueError(f"invalid option for 'closed': {closed}")
         if not left <= right:
             raise ValueError("left side of interval must be <= right side")
diff --git a/pandas/core/arrays/_arrow_utils.py b/pandas/core/arrays/_arrow_utils.py
index 4a33e0e84..c89f5554d 100644
--- a/pandas/core/arrays/_arrow_utils.py
+++ b/pandas/core/arrays/_arrow_utils.py
@@ -4,7 +4,7 @@ import json
 import numpy as np
 import pyarrow

-from pandas.core.arrays.interval import _VALID_CLOSED
+from pandas.core.arrays.interval import VALID_CLOSED

 _pyarrow_version_ge_015 = LooseVersion(pyarrow.__version__) >= LooseVersion("0.15")

@@ -83,7 +83,7 @@ if _pyarrow_version_ge_015:
         def __init__(self, subtype, closed):
             # attributes need to be set first before calling
             # super init (as that calls serialize)
-            assert closed in _VALID_CLOSED
+            assert closed in VALID_CLOSED
             self._closed = closed
             if not isinstance(subtype, pyarrow.DataType):
                 subtype = pyarrow.type_for_alias(str(subtype))
diff --git a/pandas/core/arrays/interval.py b/pandas/core/arrays/interval.py
index d76e0fd62..1dbd3cfc6 100644
--- a/pandas/core/arrays/interval.py
+++ b/pandas/core/arrays/interval.py
@@ -5,7 +5,12 @@ import numpy as np

 from pandas._config import get_option

-from pandas._libs.interval import Interval, IntervalMixin, intervals_to_interval_bounds
+from pandas._libs.interval import (
+    VALID_CLOSED,
+    Interval,
+    IntervalMixin,
+    intervals_to_interval_bounds,
+)
 from pandas.compat.numpy import function as nv
 from pandas.util._decorators import Appender

@@ -42,7 +47,6 @@ from pandas.core.construction import array
 from pandas.core.indexers import check_array_indexer
 from pandas.core.indexes.base import ensure_index

-_VALID_CLOSED = {"left", "right", "both", "neither"}
 _interval_shared_docs = {}

 _shared_docs_kwargs = dict(
@@ -475,7 +479,7 @@ class IntervalArray(IntervalMixin, ExtensionArray):
         * left and right have the same missing values
         * left is always below right
         """
-        if self.closed not in _VALID_CLOSED:
+        if self.closed not in VALID_CLOSED:
             msg = f"invalid option for 'closed': {self.closed}"
             raise ValueError(msg)
         if len(self.left) != len(self.right):
@@ -1012,7 +1016,7 @@ class IntervalArray(IntervalMixin, ExtensionArray):
         )
     )
     def set_closed(self, closed):
-        if closed not in _VALID_CLOSED:
+        if closed not in VALID_CLOSED:
             msg = f"invalid option for 'closed': {closed}"
             raise ValueError(msg)

diff --git a/pandas/core/arrays/sparse/__init__.py b/pandas/core/arrays/sparse/__init__.py
index e928db499..e9ff4b7d4 100644
--- a/pandas/core/arrays/sparse/__init__.py
+++ b/pandas/core/arrays/sparse/__init__.py
@@ -5,6 +5,6 @@ from pandas.core.arrays.sparse.array import (
     BlockIndex,
     IntIndex,
     SparseArray,
-    _make_index,
+    make_sparse_index,
 )
 from pandas.core.arrays.sparse.dtype import SparseDtype
diff --git a/pandas/core/arrays/sparse/array.py b/pandas/core/arrays/sparse/array.py
index 47c960dc9..853f7bb0b 100644
--- a/pandas/core/arrays/sparse/array.py
+++ b/pandas/core/arrays/sparse/array.py
@@ -1556,7 +1556,7 @@ def make_sparse(arr: np.ndarray, kind="block", fill_value=None, dtype=None, copy
     else:
         indices = mask.nonzero()[0].astype(np.int32)

-    index = _make_index(length, indices, kind)
+    index = make_sparse_index(length, indices, kind)
     sparsified_values = arr[mask]
     if dtype is not None:
         sparsified_values = astype_nansafe(sparsified_values, dtype=dtype)
@@ -1564,7 +1564,7 @@ def make_sparse(arr: np.ndarray, kind="block", fill_value=None, dtype=None, copy
     return sparsified_values, index, fill_value


-def _make_index(length, indices, kind):
+def make_sparse_index(length, indices, kind):

     if kind == "block" or isinstance(kind, BlockIndex):
         locs, lens = splib.get_blocks(indices)
diff --git a/pandas/core/computation/engines.py b/pandas/core/computation/engines.py
index 0cdc0f530..77a378369 100644
--- a/pandas/core/computation/engines.py
+++ b/pandas/core/computation/engines.py
@@ -130,7 +130,7 @@ class PythonEngine(AbstractEngine):
         pass


-_engines: Dict[str, Type[AbstractEngine]] = {
+ENGINES: Dict[str, Type[AbstractEngine]] = {
     "numexpr": NumExprEngine,
     "python": PythonEngine,
 }
diff --git a/pandas/core/computation/eval.py b/pandas/core/computation/eval.py
index f6a793514..630606b4d 100644
--- a/pandas/core/computation/eval.py
+++ b/pandas/core/computation/eval.py
@@ -9,8 +9,8 @@ import warnings
 from pandas._libs.lib import no_default
 from pandas.util._validators import validate_bool_kwarg

-from pandas.core.computation.engines import _engines
-from pandas.core.computation.expr import Expr, _parsers
+from pandas.core.computation.engines import ENGINES
+from pandas.core.computation.expr import PARSERS, Expr
 from pandas.core.computation.parsing import tokenize_string
 from pandas.core.computation.scope import ensure_scope

@@ -43,8 +43,8 @@ def _check_engine(engine: Optional[str]) -> str:
     if engine is None:
         engine = "numexpr" if NUMEXPR_INSTALLED else "python"

-    if engine not in _engines:
-        valid_engines = list(_engines.keys())
+    if engine not in ENGINES:
+        valid_engines = list(ENGINES.keys())
         raise KeyError(
             f"Invalid engine '{engine}' passed, valid engines are {valid_engines}"
         )
@@ -75,9 +75,9 @@ def _check_parser(parser: str):
     KeyError
       * If an invalid parser is passed
     """
-    if parser not in _parsers:
+    if parser not in PARSERS:
         raise KeyError(
-            f"Invalid parser '{parser}' passed, valid parsers are {_parsers.keys()}"
+            f"Invalid parser '{parser}' passed, valid parsers are {PARSERS.keys()}"
         )


@@ -341,7 +341,7 @@ def eval(
         parsed_expr = Expr(expr, engine=engine, parser=parser, env=env)

         # construct the engine and evaluate the parsed expression
-        eng = _engines[engine]
+        eng = ENGINES[engine]
         eng_inst = eng(parsed_expr)
         ret = eng_inst.evaluate()

diff --git a/pandas/core/computation/expr.py b/pandas/core/computation/expr.py
index 8cff6abc0..f5897277d 100644
--- a/pandas/core/computation/expr.py
+++ b/pandas/core/computation/expr.py
@@ -782,7 +782,7 @@ class Expr:
         self.env = env or Scope(level=level + 1)
         self.engine = engine
         self.parser = parser
-        self._visitor = _parsers[parser](self.env, self.engine, self.parser)
+        self._visitor = PARSERS[parser](self.env, self.engine, self.parser)
         self.terms = self.parse()

     @property
@@ -814,4 +814,4 @@ class Expr:
         return frozenset(term.name for term in com.flatten(self.terms))


-_parsers = {"python": PythonExprVisitor, "pandas": PandasExprVisitor}
+PARSERS = {"python": PythonExprVisitor, "pandas": PandasExprVisitor}
diff --git a/pandas/core/config_init.py b/pandas/core/config_init.py
index 0c23f1b4b..bfe20551c 100644
--- a/pandas/core/config_init.py
+++ b/pandas/core/config_init.py
@@ -314,9 +314,9 @@ pc_latex_multirow = """


 def table_schema_cb(key):
-    from pandas.io.formats.printing import _enable_data_resource_formatter
+    from pandas.io.formats.printing import enable_data_resource_formatter

-    _enable_data_resource_formatter(cf.get_option(key))
+    enable_data_resource_formatter(cf.get_option(key))


 def is_terminal() -> bool:
diff --git a/pandas/core/groupby/generic.py b/pandas/core/groupby/generic.py
index 72003eab2..e870187fc 100644
--- a/pandas/core/groupby/generic.py
+++ b/pandas/core/groupby/generic.py
@@ -70,9 +70,9 @@ from pandas.core.groupby.groupby import (
     GroupBy,
     _agg_template,
     _apply_docs,
-    _group_selection_context,
     _transform_template,
     get_groupby,
+    group_selection_context,
 )
 from pandas.core.groupby.numba_ import generate_numba_func, split_for_numba
 from pandas.core.indexes.api import Index, MultiIndex, all_indexes_same
@@ -230,7 +230,7 @@ class SeriesGroupBy(GroupBy[Series]):
                 raise NotImplementedError(
                     "Numba engine can only be used with a single function."
                 )
-            with _group_selection_context(self):
+            with group_selection_context(self):
                 data = self._selected_obj
             result, index = self._aggregate_with_numba(
                 data.to_frame(), func, *args, engine_kwargs=engine_kwargs, **kwargs
@@ -685,7 +685,7 @@ class SeriesGroupBy(GroupBy[Series]):
         self, normalize=False, sort=True, ascending=False, bins=None, dropna=True
     ):

-        from pandas.core.reshape.merge import _get_join_indexers
+        from pandas.core.reshape.merge import get_join_indexers
         from pandas.core.reshape.tile import cut

         if bins is not None and not np.iterable(bins):
@@ -787,7 +787,7 @@ class SeriesGroupBy(GroupBy[Series]):

         right = [diff.cumsum() - 1, codes[-1]]

-        _, idx = _get_join_indexers(left, right, sort=False, how="left")
+        _, idx = get_join_indexers(left, right, sort=False, how="left")
         out = np.where(idx != -1, out[idx], 0)

         if sort:
@@ -942,7 +942,7 @@ class DataFrameGroupBy(GroupBy[DataFrame]):
                 raise NotImplementedError(
                     "Numba engine can only be used with a single function."
                 )
-            with _group_selection_context(self):
+            with group_selection_context(self):
                 data = self._selected_obj
             result, index = self._aggregate_with_numba(
                 data, func, *args, engine_kwargs=engine_kwargs, **kwargs
diff --git a/pandas/core/groupby/groupby.py b/pandas/core/groupby/groupby.py
index 6ef2e6703..1e3e56f4f 100644
--- a/pandas/core/groupby/groupby.py
+++ b/pandas/core/groupby/groupby.py
@@ -459,9 +459,9 @@ class GroupByPlot(PandasObject):


 @contextmanager
-def _group_selection_context(groupby: "_GroupBy"):
+def group_selection_context(groupby: "_GroupBy"):
     """
-    Set / reset the _group_selection_context.
+    Set / reset the group_selection_context.
     """
     groupby._set_group_selection()
     try:
@@ -737,7 +737,7 @@ b  2""",
     def _make_wrapper(self, name: str) -> Callable:
         assert name in self._apply_allowlist

-        with _group_selection_context(self):
+        with group_selection_context(self):
             # need to setup the selection
             # as are not passed directly but in the grouper
             f = getattr(self._obj_with_exclusions, name)
@@ -868,7 +868,7 @@ b  2""",
                 # fails on *some* columns, e.g. a numeric operation
                 # on a string grouper column

-                with _group_selection_context(self):
+                with group_selection_context(self):
                     return self._python_apply_general(f, self._selected_obj)

         return result
@@ -994,7 +994,7 @@ b  2""",
         alias: str,
         npfunc: Callable,
     ):
-        with _group_selection_context(self):
+        with group_selection_context(self):
             # try a cython aggregation if we can
             try:
                 return self._cython_agg_general(
@@ -1499,7 +1499,7 @@ class GroupBy(_GroupBy[FrameOrSeries]):
             )
         else:
             func = lambda x: x.var(ddof=ddof)
-            with _group_selection_context(self):
+            with group_selection_context(self):
                 return self._python_agg_general(func)

     @Substitution(name="groupby")
@@ -1658,7 +1658,7 @@ class GroupBy(_GroupBy[FrameOrSeries]):

     @doc(DataFrame.describe)
     def describe(self, **kwargs):
-        with _group_selection_context(self):
+        with group_selection_context(self):
             result = self.apply(lambda x: x.describe(**kwargs))
             if self.axis == 1:
                 return result.T
@@ -1963,7 +1963,7 @@ class GroupBy(_GroupBy[FrameOrSeries]):
                 nth_values = list(set(n))

             nth_array = np.array(nth_values, dtype=np.intp)
-            with _group_selection_context(self):
+            with group_selection_context(self):

                 mask_left = np.in1d(self._cumcount_array(), nth_array)
                 mask_right = np.in1d(
@@ -2226,7 +2226,7 @@ class GroupBy(_GroupBy[FrameOrSeries]):
         5    0
         dtype: int64
         """
-        with _group_selection_context(self):
+        with group_selection_context(self):
             index = self._selected_obj.index
             result = self._obj_1d_constructor(self.grouper.group_info[0], index)
             if not ascending:
@@ -2287,7 +2287,7 @@ class GroupBy(_GroupBy[FrameOrSeries]):
         5    0
         dtype: int64
         """
-        with _group_selection_context(self):
+        with group_selection_context(self):
             index = self._selected_obj.index
             cumcounts = self._cumcount_array(ascending=ascending)
             return self._obj_1d_constructor(cumcounts, index)
diff --git a/pandas/core/indexes/base.py b/pandas/core/indexes/base.py
index 526dae7e2..8014b16d0 100644
--- a/pandas/core/indexes/base.py
+++ b/pandas/core/indexes/base.py
@@ -3660,7 +3660,7 @@ class Index(IndexOpsMixin, PandasObject):
         return result

     def _join_non_unique(self, other, how="left", return_indexers=False):
-        from pandas.core.reshape.merge import _get_join_indexers
+        from pandas.core.reshape.merge import get_join_indexers

         # We only get here if dtypes match
         assert self.dtype == other.dtype
@@ -3668,7 +3668,7 @@ class Index(IndexOpsMixin, PandasObject):
         lvalues = self._get_engine_target()
         rvalues = other._get_engine_target()

-        left_idx, right_idx = _get_join_indexers(
+        left_idx, right_idx = get_join_indexers(
             [lvalues], [rvalues], how=how, sort=True
         )

diff --git a/pandas/core/indexes/interval.py b/pandas/core/indexes/interval.py
index 3f72577c9..154f41bf0 100644
--- a/pandas/core/indexes/interval.py
+++ b/pandas/core/indexes/interval.py
@@ -59,7 +59,6 @@ from pandas.core.ops import get_op_result_name
 if TYPE_CHECKING:
     from pandas import CategoricalIndex  # noqa:F401

-_VALID_CLOSED = {"left", "right", "both", "neither"}
 _index_doc_kwargs = dict(ibase._index_doc_kwargs)

 _index_doc_kwargs.update(
diff --git a/pandas/core/reshape/merge.py b/pandas/core/reshape/merge.py
index 030dec369..9f19ea9ae 100644
--- a/pandas/core/reshape/merge.py
+++ b/pandas/core/reshape/merge.py
@@ -859,7 +859,7 @@ class _MergeOperation:

     def _get_join_indexers(self):
         """ return the join indexers """
-        return _get_join_indexers(
+        return get_join_indexers(
             self.left_join_keys, self.right_join_keys, sort=self.sort, how=self.how
         )

@@ -1298,7 +1298,7 @@ class _MergeOperation:
             raise ValueError("Not a valid argument for validate")


-def _get_join_indexers(
+def get_join_indexers(
     left_keys, right_keys, sort: bool = False, how: str = "inner", **kwargs
 ):
     """
diff --git a/pandas/io/formats/printing.py b/pandas/io/formats/printing.py
index edc6fbfff..0d2ca83f1 100644
--- a/pandas/io/formats/printing.py
+++ b/pandas/io/formats/printing.py
@@ -243,7 +243,7 @@ def pprint_thing_encoded(
     return value.encode(encoding, errors)


-def _enable_data_resource_formatter(enable: bool) -> None:
+def enable_data_resource_formatter(enable: bool) -> None:
     if "IPython" not in sys.modules:
         # definitely not in IPython
         return
diff --git a/pandas/tests/arrays/sparse/test_libsparse.py b/pandas/tests/arrays/sparse/test_libsparse.py
index a2f861d37..2d6e657de 100644
--- a/pandas/tests/arrays/sparse/test_libsparse.py
+++ b/pandas/tests/arrays/sparse/test_libsparse.py
@@ -8,7 +8,7 @@ import pandas.util._test_decorators as td

 from pandas import Series
 import pandas._testing as tm
-from pandas.core.arrays.sparse import BlockIndex, IntIndex, _make_index
+from pandas.core.arrays.sparse import BlockIndex, IntIndex, make_sparse_index

 TEST_LENGTH = 20

@@ -273,41 +273,43 @@ class TestSparseIndexIntersect:

 class TestSparseIndexCommon:
     def test_int_internal(self):
-        idx = _make_index(4, np.array([2, 3], dtype=np.int32), kind="integer")
+        idx = make_sparse_index(4, np.array([2, 3], dtype=np.int32), kind="integer")
         assert isinstance(idx, IntIndex)
         assert idx.npoints == 2
         tm.assert_numpy_array_equal(idx.indices, np.array([2, 3], dtype=np.int32))

-        idx = _make_index(4, np.array([], dtype=np.int32), kind="integer")
+        idx = make_sparse_index(4, np.array([], dtype=np.int32), kind="integer")
         assert isinstance(idx, IntIndex)
         assert idx.npoints == 0
         tm.assert_numpy_array_equal(idx.indices, np.array([], dtype=np.int32))

-        idx = _make_index(4, np.array([0, 1, 2, 3], dtype=np.int32), kind="integer")
+        idx = make_sparse_index(
+            4, np.array([0, 1, 2, 3], dtype=np.int32), kind="integer"
+        )
         assert isinstance(idx, IntIndex)
         assert idx.npoints == 4
         tm.assert_numpy_array_equal(idx.indices, np.array([0, 1, 2, 3], dtype=np.int32))

     def test_block_internal(self):
-        idx = _make_index(4, np.array([2, 3], dtype=np.int32), kind="block")
+        idx = make_sparse_index(4, np.array([2, 3], dtype=np.int32), kind="block")
         assert isinstance(idx, BlockIndex)
         assert idx.npoints == 2
         tm.assert_numpy_array_equal(idx.blocs, np.array([2], dtype=np.int32))
         tm.assert_numpy_array_equal(idx.blengths, np.array([2], dtype=np.int32))

-        idx = _make_index(4, np.array([], dtype=np.int32), kind="block")
+        idx = make_sparse_index(4, np.array([], dtype=np.int32), kind="block")
         assert isinstance(idx, BlockIndex)
         assert idx.npoints == 0
         tm.assert_numpy_array_equal(idx.blocs, np.array([], dtype=np.int32))
         tm.assert_numpy_array_equal(idx.blengths, np.array([], dtype=np.int32))

-        idx = _make_index(4, np.array([0, 1, 2, 3], dtype=np.int32), kind="block")
+        idx = make_sparse_index(4, np.array([0, 1, 2, 3], dtype=np.int32), kind="block")
         assert isinstance(idx, BlockIndex)
         assert idx.npoints == 4
         tm.assert_numpy_array_equal(idx.blocs, np.array([0], dtype=np.int32))
         tm.assert_numpy_array_equal(idx.blengths, np.array([4], dtype=np.int32))

-        idx = _make_index(4, np.array([0, 2, 3], dtype=np.int32), kind="block")
+        idx = make_sparse_index(4, np.array([0, 2, 3], dtype=np.int32), kind="block")
         assert isinstance(idx, BlockIndex)
         assert idx.npoints == 3
         tm.assert_numpy_array_equal(idx.blocs, np.array([0, 2], dtype=np.int32))
@@ -315,7 +317,7 @@ class TestSparseIndexCommon:

     def test_lookup(self):
         for kind in ["integer", "block"]:
-            idx = _make_index(4, np.array([2, 3], dtype=np.int32), kind=kind)
+            idx = make_sparse_index(4, np.array([2, 3], dtype=np.int32), kind=kind)
             assert idx.lookup(-1) == -1
             assert idx.lookup(0) == -1
             assert idx.lookup(1) == -1
@@ -323,12 +325,14 @@ class TestSparseIndexCommon:
             assert idx.lookup(3) == 1
             assert idx.lookup(4) == -1

-            idx = _make_index(4, np.array([], dtype=np.int32), kind=kind)
+            idx = make_sparse_index(4, np.array([], dtype=np.int32), kind=kind)

             for i in range(-1, 5):
                 assert idx.lookup(i) == -1

-            idx = _make_index(4, np.array([0, 1, 2, 3], dtype=np.int32), kind=kind)
+            idx = make_sparse_index(
+                4, np.array([0, 1, 2, 3], dtype=np.int32), kind=kind
+            )
             assert idx.lookup(-1) == -1
             assert idx.lookup(0) == 0
             assert idx.lookup(1) == 1
@@ -336,7 +340,7 @@ class TestSparseIndexCommon:
             assert idx.lookup(3) == 3
             assert idx.lookup(4) == -1

-            idx = _make_index(4, np.array([0, 2, 3], dtype=np.int32), kind=kind)
+            idx = make_sparse_index(4, np.array([0, 2, 3], dtype=np.int32), kind=kind)
             assert idx.lookup(-1) == -1
             assert idx.lookup(0) == 0
             assert idx.lookup(1) == -1
@@ -346,7 +350,7 @@ class TestSparseIndexCommon:

     def test_lookup_array(self):
         for kind in ["integer", "block"]:
-            idx = _make_index(4, np.array([2, 3], dtype=np.int32), kind=kind)
+            idx = make_sparse_index(4, np.array([2, 3], dtype=np.int32), kind=kind)

             res = idx.lookup_array(np.array([-1, 0, 2], dtype=np.int32))
             exp = np.array([-1, -1, 0], dtype=np.int32)
@@ -356,11 +360,13 @@ class TestSparseIndexCommon:
             exp = np.array([-1, 0, -1, 1], dtype=np.int32)
             tm.assert_numpy_array_equal(res, exp)

-            idx = _make_index(4, np.array([], dtype=np.int32), kind=kind)
+            idx = make_sparse_index(4, np.array([], dtype=np.int32), kind=kind)
             res = idx.lookup_array(np.array([-1, 0, 2, 4], dtype=np.int32))
             exp = np.array([-1, -1, -1, -1], dtype=np.int32)

-            idx = _make_index(4, np.array([0, 1, 2, 3], dtype=np.int32), kind=kind)
+            idx = make_sparse_index(
+                4, np.array([0, 1, 2, 3], dtype=np.int32), kind=kind
+            )
             res = idx.lookup_array(np.array([-1, 0, 2], dtype=np.int32))
             exp = np.array([-1, 0, 2], dtype=np.int32)
             tm.assert_numpy_array_equal(res, exp)
@@ -369,7 +375,7 @@ class TestSparseIndexCommon:
             exp = np.array([-1, 2, 1, 3], dtype=np.int32)
             tm.assert_numpy_array_equal(res, exp)

-            idx = _make_index(4, np.array([0, 2, 3], dtype=np.int32), kind=kind)
+            idx = make_sparse_index(4, np.array([0, 2, 3], dtype=np.int32), kind=kind)
             res = idx.lookup_array(np.array([2, 1, 3, 0], dtype=np.int32))
             exp = np.array([1, -1, 2, 0], dtype=np.int32)
             tm.assert_numpy_array_equal(res, exp)
@@ -402,25 +408,25 @@ class TestSparseIndexCommon:

 class TestBlockIndex:
     def test_block_internal(self):
-        idx = _make_index(4, np.array([2, 3], dtype=np.int32), kind="block")
+        idx = make_sparse_index(4, np.array([2, 3], dtype=np.int32), kind="block")
         assert isinstance(idx, BlockIndex)
         assert idx.npoints == 2
         tm.assert_numpy_array_equal(idx.blocs, np.array([2], dtype=np.int32))
         tm.assert_numpy_array_equal(idx.blengths, np.array([2], dtype=np.int32))

-        idx = _make_index(4, np.array([], dtype=np.int32), kind="block")
+        idx = make_sparse_index(4, np.array([], dtype=np.int32), kind="block")
         assert isinstance(idx, BlockIndex)
         assert idx.npoints == 0
         tm.assert_numpy_array_equal(idx.blocs, np.array([], dtype=np.int32))
         tm.assert_numpy_array_equal(idx.blengths, np.array([], dtype=np.int32))

-        idx = _make_index(4, np.array([0, 1, 2, 3], dtype=np.int32), kind="block")
+        idx = make_sparse_index(4, np.array([0, 1, 2, 3], dtype=np.int32), kind="block")
         assert isinstance(idx, BlockIndex)
         assert idx.npoints == 4
         tm.assert_numpy_array_equal(idx.blocs, np.array([0], dtype=np.int32))
         tm.assert_numpy_array_equal(idx.blengths, np.array([4], dtype=np.int32))

-        idx = _make_index(4, np.array([0, 2, 3], dtype=np.int32), kind="block")
+        idx = make_sparse_index(4, np.array([0, 2, 3], dtype=np.int32), kind="block")
         assert isinstance(idx, BlockIndex)
         assert idx.npoints == 3
         tm.assert_numpy_array_equal(idx.blocs, np.array([0, 2], dtype=np.int32))
@@ -428,7 +434,7 @@ class TestBlockIndex:

     def test_make_block_boundary(self):
         for i in [5, 10, 100, 101]:
-            idx = _make_index(i, np.arange(0, i, 2, dtype=np.int32), kind="block")
+            idx = make_sparse_index(i, np.arange(0, i, 2, dtype=np.int32), kind="block")

             exp = np.arange(0, i, 2, dtype=np.int32)
             tm.assert_numpy_array_equal(idx.blocs, exp)
@@ -514,17 +520,19 @@ class TestIntIndex:
             IntIndex(length=5, indices=[1, 3, 3])

     def test_int_internal(self):
-        idx = _make_index(4, np.array([2, 3], dtype=np.int32), kind="integer")
+        idx = make_sparse_index(4, np.array([2, 3], dtype=np.int32), kind="integer")
         assert isinstance(idx, IntIndex)
         assert idx.npoints == 2
         tm.assert_numpy_array_equal(idx.indices, np.array([2, 3], dtype=np.int32))

-        idx = _make_index(4, np.array([], dtype=np.int32), kind="integer")
+        idx = make_sparse_index(4, np.array([], dtype=np.int32), kind="integer")
         assert isinstance(idx, IntIndex)
         assert idx.npoints == 0
         tm.assert_numpy_array_equal(idx.indices, np.array([], dtype=np.int32))

-        idx = _make_index(4, np.array([0, 1, 2, 3], dtype=np.int32), kind="integer")
+        idx = make_sparse_index(
+            4, np.array([0, 1, 2, 3], dtype=np.int32), kind="integer"
+        )
         assert isinstance(idx, IntIndex)
         assert idx.npoints == 4
         tm.assert_numpy_array_equal(idx.indices, np.array([0, 1, 2, 3], dtype=np.int32))
diff --git a/pandas/tests/computation/test_compat.py b/pandas/tests/computation/test_compat.py
index ead102f53..9fc3ed480 100644
--- a/pandas/tests/computation/test_compat.py
+++ b/pandas/tests/computation/test_compat.py
@@ -5,7 +5,7 @@ import pytest
 from pandas.compat._optional import VERSIONS

 import pandas as pd
-from pandas.core.computation.engines import _engines
+from pandas.core.computation.engines import ENGINES
 import pandas.core.computation.expr as expr


@@ -26,8 +26,8 @@ def test_compat():
         pytest.skip("not testing numexpr version compat")


-@pytest.mark.parametrize("engine", _engines)
-@pytest.mark.parametrize("parser", expr._parsers)
+@pytest.mark.parametrize("engine", ENGINES)
+@pytest.mark.parametrize("parser", expr.PARSERS)
 def test_invalid_numexpr_version(engine, parser):
     def testit():
         a, b = 1, 2  # noqa
diff --git a/pandas/tests/computation/test_eval.py b/pandas/tests/computation/test_eval.py
index 72dc04e68..cca64a6bf 100644
--- a/pandas/tests/computation/test_eval.py
+++ b/pandas/tests/computation/test_eval.py
@@ -19,7 +19,7 @@ from pandas import DataFrame, Series, compat, date_range
 import pandas._testing as tm
 from pandas.core.computation import pytables
 from pandas.core.computation.check import NUMEXPR_VERSION
-from pandas.core.computation.engines import NumExprClobberingError, _engines
+from pandas.core.computation.engines import ENGINES, NumExprClobberingError
 import pandas.core.computation.expr as expr
 from pandas.core.computation.expr import (
     BaseExprVisitor,
@@ -46,14 +46,14 @@ from pandas.core.computation.ops import (
                 f"installed->{NUMEXPR_INSTALLED}",
             ),
         )
-        for engine in _engines
+        for engine in ENGINES
     )
 )  # noqa
 def engine(request):
     return request.param


-@pytest.fixture(params=expr._parsers)
+@pytest.fixture(params=expr.PARSERS)
 def parser(request):
     return request.param

@@ -77,7 +77,7 @@ def unary_fns_for_ne():


 def engine_has_neg_frac(engine):
-    return _engines[engine].has_neg_frac
+    return ENGINES[engine].has_neg_frac


 def _eval_single_bin(lhs, cmp1, rhs, engine):
@@ -168,7 +168,7 @@ class TestEvalNumexprPandas:
     def setup_method(self, method):
         self.setup_ops()
         self.setup_data()
-        self.current_engines = (engine for engine in _engines if engine != self.engine)
+        self.current_engines = (engine for engine in ENGINES if engine != self.engine)

     def teardown_method(self, method):
         del self.lhses, self.rhses, self.scalar_rhses, self.scalar_lhses
@@ -1921,7 +1921,7 @@ _parsers: Dict[str, Type[BaseExprVisitor]] = {
 }


-@pytest.mark.parametrize("engine", _engines)
+@pytest.mark.parametrize("engine", ENGINES)
 @pytest.mark.parametrize("parser", _parsers)
 def test_disallowed_nodes(engine, parser):
     VisitorClass = _parsers[parser]